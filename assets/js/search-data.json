{
  
    
        "post0": {
            "title": "Title",
            "content": "Dataset: https://www.kaggle.com/vjchoudhary7/customer-segmentation-tutorial-in-python. . In this notebook, I&#39;ll do clustering using KMeans (unsupervised learning) for mall customer segmentation. . import pandas as pd import numpy as np import matplotlib.pyplot as plt %matplotlib inline import seaborn as sns sns.set(style=&#39;whitegrid&#39;) import warnings warnings.filterwarnings(&#39;ignore&#39;) pd.set_option(&#39;max_columns&#39;, None) pd.set_option(&#39;max_rows&#39;, None) import os for dirname, _, filenames in os.walk(&#39;/kaggle/input&#39;): for filename in filenames: print(os.path.join(dirname, filename)) . /kaggle/input/customer-segmentation-tutorial-in-python/Mall_Customers.csv . df = pd.read_csv(&#39;/kaggle/input/customer-segmentation-tutorial-in-python/Mall_Customers.csv&#39;) df.head() . CustomerID Gender Age Annual Income (k$) Spending Score (1-100) . 0 1 | Male | 19 | 15 | 39 | . 1 2 | Male | 21 | 15 | 81 | . 2 3 | Female | 20 | 16 | 6 | . 3 4 | Female | 23 | 16 | 77 | . 4 5 | Female | 31 | 17 | 40 | . df.describe() . CustomerID Age Annual Income (k$) Spending Score (1-100) . count 200.000000 | 200.000000 | 200.000000 | 200.000000 | . mean 100.500000 | 38.850000 | 60.560000 | 50.200000 | . std 57.879185 | 13.969007 | 26.264721 | 25.823522 | . min 1.000000 | 18.000000 | 15.000000 | 1.000000 | . 25% 50.750000 | 28.750000 | 41.500000 | 34.750000 | . 50% 100.500000 | 36.000000 | 61.500000 | 50.000000 | . 75% 150.250000 | 49.000000 | 78.000000 | 73.000000 | . max 200.000000 | 70.000000 | 137.000000 | 99.000000 | . Let&#39;s check if there are any missing values. . df.isnull().any().any() . False . size = df[&#39;Gender&#39;].value_counts() plt.figure(figsize=(7,7)) plt.pie(size, colors=[&#39;lightblue&#39;, &#39;salmon&#39;], labels=[&#39;Female&#39;, &#39;Male&#39;], shadow=True, autopct=&#39;%.2f%%&#39;, explode=[0,0.05]) plt.title(&#39;Customers Gender&#39;) . Text(0.5, 1.0, &#39;Customers Gender&#39;) . plt.figure(figsize=(18,4)) plt.subplot(131) sns.distplot(df[&#39;Age&#39;]) plt.title(&#39;Distribution of Age&#39;) plt.subplot(132) sns.distplot(df[&#39;Annual Income (k$)&#39;]) plt.title(&#39;Distribution of Annual Income&#39;) plt.subplot(133) sns.distplot(df[&#39;Spending Score (1-100)&#39;]) plt.title(&#39;Distribution of Spending Score&#39;) . Text(0.5, 1.0, &#39;Distribution of Spending Score&#39;) . We can see that: . People of age around 30-35 are the most frequent visitor. | There are few customers earn above 90k Dollars, with most people have annual income around 50-90k Dollars. | Majority of people have spending score around 40-60. | . sns.heatmap(df[[&#39;Age&#39;, &#39;Annual Income (k$)&#39;, &#39;Spending Score (1-100)&#39;]].corr(), cmap=&#39;GnBu&#39;, annot=True, square=True, linewidths=0.1, linecolor=&#39;white&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fb5d9a96a10&gt; . We can see that there are no strong correlation around the heatmap, so it may hard to fit model such as regression for this problem. . plt.figure(figsize=(10,5)) plt.subplot(121) sns.boxplot(x=&#39;Gender&#39;, y=&#39;Spending Score (1-100)&#39;, data=df) plt.title(&#39;Gender vs Spending Score&#39;) plt.subplot(122) sns.boxplot(x=&#39;Gender&#39;, y=&#39;Annual Income (k$)&#39;, data=df) plt.title(&#39;Gender vs Annual Income&#39;) . Text(0.5, 1.0, &#39;Gender vs Annual Income&#39;) . plt.figure(figsize=(12,6)) sns.scatterplot(x=&#39;Annual Income (k$)&#39;, y=&#39;Spending Score (1-100)&#39;, data=df) plt.title(&#39;Annual Income vs Spending Score&#39;) . Text(0.5, 1.0, &#39;Annual Income vs Spending Score&#39;) . The graph shows that we can segment customer into 5 clusters, but let&#39;s do that by using KMeans clustering. . KMeans has a n_clusters parameter, which is a number of cluster, that we can find the optimal n_clusters by using elbow method. . from sklearn.cluster import KMeans df_1 = df[[&#39;Annual Income (k$)&#39;, &#39;Spending Score (1-100)&#39;]] inertias = [] for i in range(1,11): km = KMeans(n_clusters=i, random_state=21) km.fit(df_1) inertias.append(km.inertia_) plt.plot(range(1,11), inertias) plt.title(&#39;Elbow Method using Inertia&#39;) plt.xlabel(&#39;No of Clusters&#39;) plt.ylabel(&#39;Inertia&#39;) . Text(0, 0.5, &#39;Inertia&#39;) . The inertia starts decreasing slowly at 5 n_clusters, so we&#39;ll choose 5 clusters. . km = KMeans(n_clusters=5, random_state=21) df_1[&#39;K_Means&#39;] = km.fit_predict(df_1) # I ran the code without the labels below first, then I name the labels based on the scatterplot labels = [&#39;Low Income Low Spending&#39;, &#39;Low Income High Spending&#39;, &#39;Average &#39;, &#39;High Income Low Spending&#39;, &#39;High Income High Spending&#39;] plt.figure(figsize=(12,6)) sns.scatterplot(x=&#39;Annual Income (k$)&#39;, y=&#39;Spending Score (1-100)&#39;, hue=&#39;K_Means&#39;, data=df_1, palette=&#39;bright&#39;) plt.legend(labels=labels, bbox_to_anchor=(1.05, 1), loc=&#39;upper left&#39;) plt.title(&#39;KMeans Clustering of Annual Income vs Spending Score&#39;) . Text(0.5, 1.0, &#39;KMeans Clustering of Annual Income vs Spending Score&#39;) . plt.figure(figsize=(12,6)) sns.scatterplot(x=&#39;Age&#39;, y=&#39;Spending Score (1-100)&#39;, data=df) plt.title(&#39;Age vs Spending Score&#39;) . Text(0.5, 1.0, &#39;Age vs Spending Score&#39;) . It&#39;s a bit hard to see the segmentation of Age vs Spending Score, thus we&#39;ll make use of KMeans again. . df_2 = df[[&#39;Age&#39;, &#39;Spending Score (1-100)&#39;]] inertias = [] for i in range(1,11): km = KMeans(n_clusters=i, random_state=21) km.fit(df_2) inertias.append(km.inertia_) plt.plot(range(1,11), inertias) plt.title(&#39;Elbow Method using Inertia&#39;) plt.xlabel(&#39;No of Clusters&#39;) plt.ylabel(&#39;Inertia&#39;) . Text(0, 0.5, &#39;Inertia&#39;) . km = KMeans(n_clusters=4, random_state=21) df_2[&#39;K_Means&#39;] = km.fit_predict(df_2) # I ran the code without the labels below first, then I name the labels based on the scatterplot labels = [&#39;Target Customers (Young)&#39;, &#39;Priority Customers&#39;, &#39;Target Customers (Old)&#39;, &#39;Usual Customers&#39;] plt.figure(figsize=(12,6)) sns.scatterplot(x=&#39;Age&#39;, y=&#39;Spending Score (1-100)&#39;, hue=&#39;K_Means&#39;, data=df_2, palette=&#39;bright&#39;) plt.legend(labels=labels, bbox_to_anchor=(1.05, 1), loc=&#39;upper left&#39;) plt.title(&#39;KMeans Clustering of Age vs Spending Score&#39;) . Text(0.5, 1.0, &#39;KMeans Clustering of Age vs Spending Score&#39;) . To summarize, we can do clustering on unlabeled data by using KMeans, and in the process, we do some EDA and find the optimal number of clusters by using elbow method. Thanks for reading this notebook :) .",
            "url": "https://mpaujan21.github.io/mpaujan21-portfolio/2020/10/26/Mall-Customer-Segmentation-with-KMeans.html",
            "relUrl": "/2020/10/26/Mall-Customer-Segmentation-with-KMeans.html",
            "date": " • Oct 26, 2020"
        }
        
    
  
    
  
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://mpaujan21.github.io/mpaujan21-portfolio/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://mpaujan21.github.io/mpaujan21-portfolio/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}