{
  
    
        "post0": {
            "title": "Title",
            "content": "Dataset: https://www.kaggle.com/shivam2503/diamonds In this notebook, I will try to implement machine learning model (regression) to predict the price of diamonds. This simple notebook just focus on the EDA (Exploratory Data Analysis) and simple machine learning. . Data Description: . price: price in US dollars (326--18,823) . carat: weight of the diamond (0.2--5.01) . cut: quality of the cut (Fair, Good, Very Good, Premium, Ideal) . color: diamond colour, from J (worst) to D (best) . clarity: a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best)) . x: length in mm (0--10.74) . y: width in mm (0--58.9) . z: depth in mm (0--31.8) . depth: total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43--79) . table: width of top of diamond relative to widest point (43--95) . 1. Data Handling . 1.1 Import Module and Preview Data . import pandas as pd import numpy as np import matplotlib.pyplot as plt %matplotlib inline import seaborn as sns import warnings warnings.filterwarnings(&#39;ignore&#39;) pd.set_option(&#39;max_columns&#39;, None) pd.set_option(&#39;max_rows&#39;, None) import os for dirname, _, filenames in os.walk(&#39;/kaggle/input&#39;): for filename in filenames: print(os.path.join(dirname, filename)) . /kaggle/input/diamonds/diamonds.csv . df = pd.read_csv(&#39;/kaggle/input/diamonds/diamonds.csv&#39;) df.head() . Unnamed: 0 carat cut color clarity depth table price x y z . 0 1 | 0.23 | Ideal | E | SI2 | 61.5 | 55.0 | 326 | 3.95 | 3.98 | 2.43 | . 1 2 | 0.21 | Premium | E | SI1 | 59.8 | 61.0 | 326 | 3.89 | 3.84 | 2.31 | . 2 3 | 0.23 | Good | E | VS1 | 56.9 | 65.0 | 327 | 4.05 | 4.07 | 2.31 | . 3 4 | 0.29 | Premium | I | VS2 | 62.4 | 58.0 | 334 | 4.20 | 4.23 | 2.63 | . 4 5 | 0.31 | Good | J | SI2 | 63.3 | 58.0 | 335 | 4.34 | 4.35 | 2.75 | . df.drop(&#39;Unnamed: 0&#39;, axis=1, inplace=True) . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 53940 entries, 0 to 53939 Data columns (total 10 columns): # Column Non-Null Count Dtype -- -- 0 carat 53940 non-null float64 1 cut 53940 non-null object 2 color 53940 non-null object 3 clarity 53940 non-null object 4 depth 53940 non-null float64 5 table 53940 non-null float64 6 price 53940 non-null int64 7 x 53940 non-null float64 8 y 53940 non-null float64 9 z 53940 non-null float64 dtypes: float64(6), int64(1), object(3) memory usage: 4.1+ MB . 1.2 Univariate and Bivariate Data Analysis . plt.figure(figsize=(12,10)) sns.heatmap(df.corr(), annot=True, square=True, cmap=&#39;RdGy&#39;, linewidths=0.1, linecolor=&#39;white&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fe686c9e910&gt; . We can see that x, y, z, carat have strong correlation with price, while table and depth don&#39;t have. Also, table and depth don&#39;t have a significant relation with other features as well. . sns.pairplot(df) . &lt;seaborn.axisgrid.PairGrid at 0x7fe686805ed0&gt; . 1.3 Check Missing Values . df.describe(include=&#39;all&#39;) . carat cut color clarity depth table price x y z . count 53940.000000 | 53940 | 53940 | 53940 | 53940.000000 | 53940.000000 | 53940.000000 | 53940.000000 | 53940.000000 | 53940.000000 | . unique NaN | 5 | 7 | 8 | NaN | NaN | NaN | NaN | NaN | NaN | . top NaN | Ideal | G | SI1 | NaN | NaN | NaN | NaN | NaN | NaN | . freq NaN | 21551 | 11292 | 13065 | NaN | NaN | NaN | NaN | NaN | NaN | . mean 0.797940 | NaN | NaN | NaN | 61.749405 | 57.457184 | 3932.799722 | 5.731157 | 5.734526 | 3.538734 | . std 0.474011 | NaN | NaN | NaN | 1.432621 | 2.234491 | 3989.439738 | 1.121761 | 1.142135 | 0.705699 | . min 0.200000 | NaN | NaN | NaN | 43.000000 | 43.000000 | 326.000000 | 0.000000 | 0.000000 | 0.000000 | . 25% 0.400000 | NaN | NaN | NaN | 61.000000 | 56.000000 | 950.000000 | 4.710000 | 4.720000 | 2.910000 | . 50% 0.700000 | NaN | NaN | NaN | 61.800000 | 57.000000 | 2401.000000 | 5.700000 | 5.710000 | 3.530000 | . 75% 1.040000 | NaN | NaN | NaN | 62.500000 | 59.000000 | 5324.250000 | 6.540000 | 6.540000 | 4.040000 | . max 5.010000 | NaN | NaN | NaN | 79.000000 | 95.000000 | 18823.000000 | 10.740000 | 58.900000 | 31.800000 | . Values of 0 in x, y, z is not possible, because they are length, width, and depth according to the description. We&#39;ll check how many rows have that condition. . df[[&#39;x&#39;,&#39;y&#39;,&#39;z&#39;]] = df[[&#39;x&#39;, &#39;y&#39;, &#39;z&#39;]].replace(0, np.NaN) . df.isnull().sum() . carat 0 cut 0 color 0 clarity 0 depth 0 table 0 price 0 x 8 y 7 z 20 dtype: int64 . Since our dataset is big, dropping 20 rows shouldn&#39;t cost us. . df.dropna(inplace=True) . 1.4 Categorical Data . plt.figure(figsize=(20,20)) plt.subplot(321) sns.countplot(x=&#39;cut&#39;, data=df, order=[&#39;Fair&#39;, &#39;Good&#39;, &#39;Very Good&#39;, &#39;Premium&#39;, &#39;Ideal&#39;]) plt.title(&#39;Quality of the Cut Countplot&#39;) plt.subplot(322) sns.boxplot(x=&#39;cut&#39;, y=&#39;price&#39;, data=df, order=[&#39;Fair&#39;, &#39;Good&#39;, &#39;Very Good&#39;, &#39;Premium&#39;, &#39;Ideal&#39;]) plt.title(&#39;Quality of the Cut vs Price Boxplot&#39;) plt.subplot(323) sns.countplot(x=&#39;color&#39;, data=df, order=[&#39;J&#39;, &#39;I&#39;, &#39;H&#39;, &#39;G&#39;, &#39;F&#39;, &#39;E&#39;, &#39;D&#39;]) plt.title(&#39;Diamond Colour Countplot, from Worst to Best&#39;) plt.subplot(324) sns.boxplot(x=&#39;color&#39;, y=&#39;price&#39;, data=df, order=[&#39;J&#39;, &#39;I&#39;, &#39;H&#39;, &#39;G&#39;, &#39;F&#39;, &#39;E&#39;, &#39;D&#39;]) plt.title(&#39;Diamond Colour vs Price Boxplot&#39;) plt.subplot(325) sns.countplot(x=&#39;clarity&#39;, data=df, order=[&#39;I1&#39;, &#39;SI2&#39;, &#39;SI1&#39;, &#39;VS2&#39;, &#39;VS1&#39;, &#39;VVS2&#39;, &#39;VVS1&#39;, &#39;IF&#39;]) plt.title(&#39;Diamond Clarity Countplot, from Worst to Best&#39;) plt.subplot(326) sns.boxplot(x=&#39;clarity&#39;, y=&#39;price&#39;, data=df, order=[&#39;I1&#39;, &#39;SI2&#39;, &#39;SI1&#39;, &#39;VS2&#39;, &#39;VS1&#39;, &#39;VVS2&#39;, &#39;VVS1&#39;, &#39;IF&#39;]) plt.title(&#39;Diamond Clarity vs Price Boxplot&#39;) . Text(0.5, 1.0, &#39;Diamond Clarity vs Price Boxplot&#39;) . Overall, median prices are very low compared to the the highest price values for all the categories in colors, cut and clarity (and it looks like a gallery of swords). Next, we&#39;ll convert the categorical data into numerical data using one hot encoding. . For reference: https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html . clean_df = pd.get_dummies(df) clean_df.head() . carat depth table price x y z cut_Fair cut_Good cut_Ideal cut_Premium cut_Very Good color_D color_E color_F color_G color_H color_I color_J clarity_I1 clarity_IF clarity_SI1 clarity_SI2 clarity_VS1 clarity_VS2 clarity_VVS1 clarity_VVS2 . 0 0.23 | 61.5 | 55.0 | 326 | 3.95 | 3.98 | 2.43 | 0 | 0 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | . 1 0.21 | 59.8 | 61.0 | 326 | 3.89 | 3.84 | 2.31 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | . 2 0.23 | 56.9 | 65.0 | 327 | 4.05 | 4.07 | 2.31 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | . 3 0.29 | 62.4 | 58.0 | 334 | 4.20 | 4.23 | 2.63 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | . 4 0.31 | 63.3 | 58.0 | 335 | 4.34 | 4.35 | 2.75 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | . 1.5 Data Scaling . from sklearn.preprocessing import StandardScaler numericals = pd.DataFrame(StandardScaler().fit_transform(clean_df[[&#39;carat&#39;,&#39;depth&#39;,&#39;x&#39;,&#39;y&#39;,&#39;z&#39;,&#39;table&#39;]]), columns=[&#39;carat&#39;,&#39;depth&#39;,&#39;x&#39;,&#39;y&#39;,&#39;z&#39;,&#39;table&#39;], index=clean_df.index) . clean_df[[&#39;carat&#39;,&#39;depth&#39;,&#39;x&#39;,&#39;y&#39;,&#39;z&#39;,&#39;table&#39;]] = numericals[[&#39;carat&#39;,&#39;depth&#39;,&#39;x&#39;,&#39;y&#39;,&#39;z&#39;,&#39;table&#39;]] clean_df.head() . carat depth table price x y z cut_Fair cut_Good cut_Ideal cut_Premium cut_Very Good color_D color_E color_F color_G color_H color_I color_J clarity_I1 clarity_IF clarity_SI1 clarity_SI2 clarity_VS1 clarity_VS2 clarity_VVS1 clarity_VVS2 . 0 -1.198204 | -0.174203 | -1.099725 | 326 | -1.591573 | -1.539219 | -1.580084 | 0 | 0 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | . 1 -1.240417 | -1.361090 | 1.585988 | 326 | -1.645173 | -1.662014 | -1.750896 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | . 2 -1.198204 | -3.385781 | 3.376463 | 327 | -1.502241 | -1.460280 | -1.750896 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | . 3 -1.071566 | 0.454149 | 0.243131 | 334 | -1.368242 | -1.319943 | -1.295396 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | . 4 -1.029353 | 1.082501 | 0.243131 | 335 | -1.243176 | -1.214690 | -1.124583 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | . plt.figure(figsize=(25,25)) sns.heatmap(clean_df.corr(), annot=True, cmap=&#39;RdYlGn&#39;, cbar_kws={&#39;shrink&#39;: .25}) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fe68645f110&gt; . It&#39;s pretty cool that the stats are still same even after standardization. . 1.6 Split into Train and Test Data . from sklearn.model_selection import train_test_split X = clean_df.drop([&#39;price&#39;], axis=1) y = clean_df[&#39;price&#39;] X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21) . 2. Model Training . from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score from sklearn.linear_model import LinearRegression, Ridge, Lasso . Reference for the metrics I use: https://towardsdatascience.com/metrics-to-understand-regression-models-in-plain-english-part-1-c902b2f4156f . 2.1 Linear Regression . lr = LinearRegression() lr.fit(X_train, y_train) y_pred = lr.predict(X_test) print(&#39;Accuracy: &#39;, lr.score(X_test, y_test)) print(&#39;Mean Absolute Error: &#39;, mean_absolute_error(y_test, y_pred)) print(&#39;Mean Squared Error: &#39;, mean_squared_error(y_test, y_pred)) print(&#39;R Squared: &#39;, r2_score(y_test, y_pred)) . Accuracy: 0.9216700049231721 Mean Absolute Error: 733.5299925732875 Mean Squared Error: 1236679.2708149399 R Squared: 0.9216700049231721 . 2.2 Ridge and Lasso Regression . ridge = Ridge() ridge.fit(X_train, y_train) y_pred = ridge.predict(X_test) print(&#39;Accuracy: &#39;, ridge.score(X_test, y_test)) print(&#39;Mean Absolute Error: &#39;, mean_absolute_error(y_test, y_pred)) print(&#39;Mean Squared Error: &#39;, mean_squared_error(y_test, y_pred)) print(&#39;R Squared: &#39;, r2_score(y_test, y_pred)) . Accuracy: 0.9216661753597207 Mean Absolute Error: 733.5416630107638 Mean Squared Error: 1236739.7322222444 R Squared: 0.9216661753597207 . lasso = Lasso() lasso.fit(X_train, y_train) y_pred = lasso.predict(X_test) print(&#39;Accuracy: &#39;, lasso.score(X_test, y_test)) print(&#39;Mean Absolute Error: &#39;, mean_absolute_error(y_test, y_pred)) print(&#39;Mean Squared Error: &#39;, mean_squared_error(y_test, y_pred)) print(&#39;R Squared: &#39;, r2_score(y_test, y_pred)) . Accuracy: 0.9216016627043966 Mean Absolute Error: 732.0438147146006 Mean Squared Error: 1237758.2623966236 R Squared: 0.9216016627043966 . Here, the optimal accuracy is by using Linear Regression. Thank you for reading this notebook :) .",
            "url": "https://mpaujan21.github.io/mpaujan21-portfolio/2020/10/23/Predict-Diamond-Prices-using-Regression.html",
            "relUrl": "/2020/10/23/Predict-Diamond-Prices-using-Regression.html",
            "date": " • Oct 23, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://mpaujan21.github.io/mpaujan21-portfolio/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://mpaujan21.github.io/mpaujan21-portfolio/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://mpaujan21.github.io/mpaujan21-portfolio/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}